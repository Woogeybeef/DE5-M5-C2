# Task: 

## Part A - Sklearn has some useful datasets. Research and load the "titanic.csv" dataset.

 1. Check for missing values and handle them.
 2. Check for duplicate rows and remove them.
 3. Inspect the "Sex" column for inconsistencies and standardize values.
 4. Detect and handle outliers in the "Age" and "Fare" columns.
 5. Create a new "Family_Size" feature based on "SibSp" and "Parch".
 6. Convert the "Embarked" column to numerical values using label encoding.
 7. If a "Ticket_Purchase_Date" column existed, convert it to datetime and extract the year and month.
 8. Clean the "Name" column by removing titles and converting to lowercase.
 9. Bin the "Age" column into categories like 'Child', 'Teen', 'Adult', and 'Senior'.

## Part B - Upload your analysis to the main repo under Day_3_Task/Submissions with a folder with your name!

 1. Delete your old forked repo.
 2. In the orginal repo, create a new branch with your name using "git checkout -b branchName".
 3. Look up how to create a pull request. Set me as the reviewer (niroshsuthagar-qa).
 4. I will review this and leave a feedback. 
 5. Once approved, push your changes and merge your branch.
 6. Once complete and on the main repo, you may delete your old branch.

## Stretch:

Combined everything you've learnt:
- Create a new GitHub repo called "Python EDA". 
- Make a directory called Pandas_Data_Prep
- Within this, you have one task: Show off your data pre-processing skills. Thing to include...
	 1. Check for missing values and handle them appropriately.
	 2. Check for duplicate rows and remove them.
	 3. Inspect and standardize categorical columns for inconsistencies (e.g., case sensitivity).
	 4. Detect and handle outliers in numeric columns.
	 5. Create new features or transform existing ones (e.g., from columns like "Date" or "Amount").
	 6. Convert categorical columns to numerical values (e.g., using label encoding or one-hot encoding).
	 7. Handle dates: Convert date columns to datetime format and extract useful features (e.g., year, month).
	 8. Clean text columns by removing special characters, extra spaces, and converting to lowercase.
	 9. Bin numeric columns into categories (e.g., grouping ages into categories like 'Young', 'Middle-aged', 'Old').
	 10. Ensure the integrity of numerical data by ensuring no invalid values (e.g., negative ages or impossible values).
	 11. Check for inconsistent or unexpected data types and correct them.
	 12. Normalize or standardize numeric columns when needed.
	 13. Drop irrelevant columns or rows that will not be useful for analysis.

Dataset: 
- You may chose any dataset.
- There is however a famous public dataset called "IMDb Movie Dataset". 
- This can be found on Kaggle or IMDb's official website: https://datasets.imdbws.com/ 
- If you use the imdb web link, this will be Tab Separated Values with the gzip compression.
- pd.read_csv() will work with a few additional arguments...

## Stretch 2

Use Matplotlib to load in an image from the internet. Split the image into three images with the red, green and blue channels sepated. 

Visualise these new images.